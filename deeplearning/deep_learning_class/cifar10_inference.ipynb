{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR10 데이터셋 로딩 및 추론을 할 때 필요한 파이썬 모듈을 임포팅하기 "
      ],
      "metadata": {
        "id": "6Sn4j8-_sxPN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0DhLsXoBsShQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model  # TensorFlow is required for Keras to work\n",
        "import cv2  # Install opencv-python\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR10 추론 파일을 로드하기. 추론파일: 트레이닝을 통해 계수를 최적화한 인공신경망을 파일로 만들어 저장한 것. 이 추론파일을 사용해서 feedforward 측 추론/예측을 진행함. \n",
        "코랩에서 추론파일을 사용할 때는 추론파일인 \"cifar10.h5\"을 코랩 디스크에 미리 업로드 해 놓아야 함 \n"
      ],
      "metadata": {
        "id": "ZJcknYAstAVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 추론 파일을 로드 함 \n",
        "model = load_model('./cifar10.h5')\n",
        "\n",
        "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "\t\"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "metadata": {
        "id": "svUmiz3zsTpc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "내 이미지를 추론파일을 통해서 예측해 보기 \n",
        "이제 인터넷에서 CIFAR10 데이터 종류 중 하나를 선택해서 코랩으로 옮기기. OpenCV를 이용해서 인터넷에서 예를 들어'비행기'이미지를 코랩으로 업로드 함 "
      ],
      "metadata": {
        "id": "Itik5Veit3L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 내가 판단할 이미지를 로드 OpenCV로 한다.\n",
        "img = cv2.imread('plane.png')\n",
        "cv2_imshow(img)\n",
        "cv2.waitKey(2000)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "eMLbuE94tvcV",
        "outputId": "922fa490-7798-4968-a56d-3d694f804e5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FD710EBFD90>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "내 이미지 사이즈 조절하기. \n",
        "CIFAR10 추론파일은 32x32x3인 이미지만 추론을 할 수 있음. 따라서 내 이미지의 사이즈를 32x32x3으로 축소해야 함. OpenCV 라이브러리를 이용해서 사이즈를 추론파일에 입력할 수 있도록 조정함 "
      ],
      "metadata": {
        "id": "30awghlwuVrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_resized = cv2.resize(img, (32,32))\n",
        "cv2_imshow(img_resized)\n",
        "cv2.waitKey(2000)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "TT694y0JvH7f",
        "outputId": "c54a898d-c660-4ee2-9777-7cdf8673bfb5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FD710EBFE20>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJZElEQVR4nAXB2Y8dWX0A4LP8TtWp9W59l97stt1ux4zGHhiDRiYJGfECLyhv+e/CPxBFCEWRIuUBIQUemJFRBpuJ8d7r7bvVvVV1Tp0934d/9o8/XVeVJ3GIhunoTjYc5/09RqMkBqCo2qyD1b3+wDiilOq6jifcIddIUfZ7LiCtNEOUUprnRZZlnDGtJMEBCNJK42Dh5auXy2WF+JCPcOH2Jgle+za4JsJBd0JJ4Z3BdBmAe2uB0DiO205ob0cdRpQoZTgkWjXWrbM0ZQQziglBphPG2BgoYEhQjPjobm96MhxPsjTBGHdKKtNhHJIkChYpH9JhLxibsAg5F0e00wpbE0dpkkEc8RZbHwhGFmGaZrloG2MNwmS7q8FiDkUxODyjyajzTK8b4p0VEkUk75dxBPW2QgBpMWx3ddtp00mMQpblUhtwJI6ZcQ5TMEpFLLKebBoVHEI09t6qdgsQD+I4SbIeK8fOO4QcBUoIMl4BgA8glSM0VLe3zjghau1EmeROIY9owITHtGtlydIQQHedNTIg3zWVEZUVDTEd8P6YsoJyHihJksRZg5HXIQSrjXYmeO1CBKHVNXXOO+GdNW3dri89YbgplzdGbOXp3p2jyWRb4NVGtU3T1Vu5XW7PPwB1kI0PbFRGaW4CDgj5gIVUGJFeMeJZttzuyrJnunp5+ZGqBvkI0kPJoFp9oEEFzIqy9+wHz931LojA9nogFGkaxuJidjydTLrdHJJiWGkAFqdxaqSy3gz6/RACcbozJs9Ttbjafnxr6wWygiZ3v/iHf873j959+283b/6ovQ0EFlWtGsGKAjvEOKc8Yji1zh4c36nXBYyGk24tARMjGqslxeCMQIhoI8tBPzh9dfHO7dYRBEKp42UNE7Xms/IhGV7fVnMt1OvXL7wlZWamPQQEpb1e8IXR3U6HbHwC471Bkg8YIZtd1bTGOeKRBxZ4nnNkXr/7a6vamHOIeJollg7mb74FbWc9xQfjEuHOGqlFEK21WhuMMMKEURIAmFI2uACMIMYwQojxOEMpQUAI8cj0kri+WW6Wgg/vo06lGT988KhThFG72e22FLKoeDAY3Xn44E+f3l++/l5B1IQA1kZAWMS89xh5gjGYTkqDLUK7tiVGc2Jr0dRiB8eHtQ147y47eIA78fTssAuR2W5G/YSu0P7suG2rh393Px2Ujwdlvdhst5ssYnEgzhvkvTUOYRJCAIeddSGEkPAkLXK5uFpcvA8MrubRYt6xycOH//Tz9eXb8WExG+3NF7dZv888oSS6XNxWHK6rRXN9mTLmy36QkkDABDvvMSaEYBQc5P2+Bds1jTNhW2/nnz42TUN4snt/HfHp3cPDewd9XzPG0U+eHl3e8IVNOuS6th2n+97pPMMH2dGsX9ys6tX8lmGjdBcI4nHWSM0iBquqrjUQzBBFlMK2EVkx4Fl/t5Gjg8nPnhzqi7/oN6+H+891VT19MBWILJT2ob+63RmdDIf7sasGT9h1JX/7n/+zOL9gEcUIoSAJMsYQQJg20mEULCIUO2Q2YbfTKmS9/a+//vFXj47+9df/nmczqenbd5c/uD87HfE6ZLdrMfCJkFrUy3vj/slsVDYSlaSLHCZYG+MsdgGDtYACNsYRghEBIwPyOB0NbTo7e/ajr54/bm43WxsfHd332I8nM9tZXQlrNUiTI3dx+fabv3ynv3o+mo1u6x1KWXayR4h32mllq8U2rRU4672SeRYxAE3oYHZKEn589+Trv3/65NH+r//458Hxnc8/mz0YR70Umk7UO3l+Nb+Yb4RxvEjY3t6Lq/PD/WkjrJJh02IZXMCBxQmbRTjeAVAm6g3uXJImgdB0NKmuz3/xowe/+PxogFBbm17R++JsPIT2Ty9etlJVu92ny6V2FDg/vHd4evYko7ZPmYlY18HlR+GsR8RS2mSjdHQwhU4qiFPKsSXMukDz5Ff/8quf//L5dK/867u5JXRbV//3YeHqq9/85ncsyRvV9aazrCjPL95bok8Ohl9+fhY7dFGtcSes3EDAXnYhNF0TUP8x6OCdR95iE2zAuIz5l19+wVj84s+v3l5tOqXWm/rVm/MkNJ1jFPKMl73B+GZ+bYxtavHp/flLhOqmCcAnsS3tiidJUqQxJDtRW2/BI6StTxk46yzSg970P377Xy+nw+P9yVbomLEyyykBxrLRZLapZUyT5WLltEl40TT6mxd/e/39tbSKMkSJy44ynaEuJtbzBA3uffYYsPcUIg8cE5TRYLS/WS5vFs3OJBT50WA4PugrZ2+uLgMKQIi1mmGa8gx56y0NGG21w55sxE7GWh0UVdJqX5O2u1+ORpM9EmOSxNyiwJN0MpooE6JiZOPefKuXta6FGJbxKCPPnjxKwJOgAXvRNMh5oBEwbq1dXLy+evXN9dvvdnYNfR5FzDZNkO2oyJyQhECklI6Cj6mXRnhKE56Oi6yXRnuT6WJTGy1Oj8exFz/98WfPvnjMgaimlUJgjD3CV5fXN+8/SdGkeTIZjlmHs2u8dzu4x8+O+kc3r94AGU9XK+OdRG3rSACAUVkyFu1aCSwBjf7wh2/mj+7fXFxgQlicxpRmSSKbVkqprY2T/OyHz8uCW2qFcd255DUp0slnZz+c9ifvr7+F6PgOxz1x/iYs5rHTkOdb0TbeEURXi7Vt6q3ptoEO8mJ9M+/aCxz8aDw1Hm+qTZzFRa9PaOS0YoCIalmjic9mx6ej2cH84lwsVsAGpVhIOhmkGVLzpdZdGQHS2hmvnNnIbZxkneiWnXRGO+NoCGLXJGXZK0sh5Wa1zPKcEBwsTiBCPKZRdHJ6EoR89fvf377+XwAOUclJPlQSfMJgsyMOTXjimauUgzSKgKWU+qC00TgEFHCnA+ocAxZHaLOpjJZlv0cIREAsEvVybpvNtq2//91/IzEH1jQ5RV2Wh4TxOPO9ntw1813jROM6M4oKxrhSlgAgEtGYEYwhTxEQ6ywkUdov6/Xah3o0LLUVqw9/O//u+3I4TY+mnqCitwfo4wWvlB0XJuEo78FwKNpGVFW02qDVhnoagnfOOY8QIphgAEqcRDYYz9bCCukYONFUyGm5W6/efGhXlWv1rDc7vPsYyR3sMfcsMsqrpSW4x/m4b8nAi2GyruiyglZG1pGAvPWd7KIookB9V3eN1IEVpNgRD8aELI4Z11G/j+5nTz9/+uTR6emJ+OonzdXF/wMgp9uTQhEdpgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "내 이미지 노말라이징 \n",
        "내가 업로드 한 이미지는 한 픽셀마다 3개의 0 ~ 255인 숫자로 구성되어 있음. 이 숫자의 범위를 0 ~ 1로 조정함. 이렇게 하면 feedforwarding 예측 성능이 향상됨 "
      ],
      "metadata": {
        "id": "_QPrCfa1vaUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing \n",
        "img_norm = img.astype('float')/255.0\n",
        "print(img_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcOSyhIOv59J",
        "outputId": "4513cfb5-15f2-419b-9691-aaa315906dff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.23137255 0.24313725 0.24705882]\n",
            "  [0.16862745 0.18039216 0.17647059]\n",
            "  [0.19607843 0.18823529 0.16862745]\n",
            "  ...\n",
            "  [0.61960784 0.51764706 0.42352941]\n",
            "  [0.59607843 0.49019608 0.4       ]\n",
            "  [0.58039216 0.48627451 0.40392157]]\n",
            "\n",
            " [[0.0627451  0.07843137 0.07843137]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.07058824 0.03137255 0.        ]\n",
            "  ...\n",
            "  [0.48235294 0.34509804 0.21568627]\n",
            "  [0.46666667 0.3254902  0.19607843]\n",
            "  [0.47843137 0.34117647 0.22352941]]\n",
            "\n",
            " [[0.09803922 0.09411765 0.08235294]\n",
            "  [0.0627451  0.02745098 0.        ]\n",
            "  [0.19215686 0.10588235 0.03137255]\n",
            "  ...\n",
            "  [0.4627451  0.32941176 0.19607843]\n",
            "  [0.47058824 0.32941176 0.19607843]\n",
            "  [0.42745098 0.28627451 0.16470588]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.81568627 0.66666667 0.37647059]\n",
            "  [0.78823529 0.6        0.13333333]\n",
            "  [0.77647059 0.63137255 0.10196078]\n",
            "  ...\n",
            "  [0.62745098 0.52156863 0.2745098 ]\n",
            "  [0.21960784 0.12156863 0.02745098]\n",
            "  [0.20784314 0.13333333 0.07843137]]\n",
            "\n",
            " [[0.70588235 0.54509804 0.37647059]\n",
            "  [0.67843137 0.48235294 0.16470588]\n",
            "  [0.72941176 0.56470588 0.11764706]\n",
            "  ...\n",
            "  [0.72156863 0.58039216 0.36862745]\n",
            "  [0.38039216 0.24313725 0.13333333]\n",
            "  [0.3254902  0.20784314 0.13333333]]\n",
            "\n",
            " [[0.69411765 0.56470588 0.45490196]\n",
            "  [0.65882353 0.50588235 0.36862745]\n",
            "  [0.70196078 0.55686275 0.34117647]\n",
            "  ...\n",
            "  [0.84705882 0.72156863 0.54901961]\n",
            "  [0.59215686 0.4627451  0.32941176]\n",
            "  [0.48235294 0.36078431 0.28235294]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening \n",
        "내 이미지를 사이즈 조정 -> 노말라이징을 한 다음에는 이미지의 픽셀숫자 배열을 flattening을 함. 32x32x3인 이미지를 1x(32x32x3)으로 변경해야함 CIFAR10 신경망에 입력이 가능함   "
      ],
      "metadata": {
        "id": "swZ5BicPv8Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flattening \n",
        "img_flat = img_norm.reshape((3072,1))\n",
        "#print(img_flat.shape)"
      ],
      "metadata": {
        "id": "LMpvEDFsv8DT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "추론하기 \n",
        "이제 내 이미지를 전처리해서 추론파일에 입력할 준비가 됨. 전처리된 내 이미지를 추론파일에 입력해서 예측을 실행 "
      ],
      "metadata": {
        "id": "f0yoBkj9we7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 추론하기, inference, feed-forward \n",
        "## X -> img_flat에 []을 한번더 씌운 것 \n",
        "X = np.asarray([img_flat])\n",
        "#print(X.shape)\n",
        "# 여기서 입력이미지를 추론파일에 곱하는 것 \n",
        "## return 값은 softmax\n",
        "predictions = model(X, training=False)\n",
        "print(predictions)\n",
        "print(np.argmax(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDATSnwnwqgu",
        "outputId": "ff8d7d78-fb11-4293-87e5-39572e3b0e6c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1.2043898e-06 2.3357450e-07 9.3480294e-06 2.0474745e-06 4.5847282e-06\n",
            "  1.4673181e-04 9.9973506e-01 1.0083469e-04 4.0405821e-12 2.0529332e-10]], shape=(1, 10), dtype=float32)\n",
            "6\n"
          ]
        }
      ]
    }
  ]
}