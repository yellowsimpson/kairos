{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**구글 텐서플로 라이브러리 임포트** <br>\n",
        "CIFAR10 데이터셋은 컬러 이미지셋이므로 기존 neural network로는 분류가 쉽지 않다. 따라서 이미지 분류 전용의 CNN을 사용하려 한다. CNN 역시 tensorflow계열의 딥러닝 라이브러리이므로 필요한 파이썬 라이브러리를 임포트한다. "
      ],
      "metadata": {
        "id": "PvBnv2ppIUHO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SsSoK6ZNH7Pl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Activation \n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CIFAR10 데이터셋 다운로드** <br>\n",
        "CIFAR10 데이터셋은 이미지 딥러닝 교육에 많이 사용되는 데이터셋으로 구글의 파이썬 명령 하나로 서버에서 다운로드 받을 수 있다. trainX는 트레이닝용 입력 이미지 데이터(비행기 이미지), trainY는 입력 이미지의 결과값 (비행기) 이다. 이미지 사이즈는 32x32이다. trainX.shpae 명령으로 사이즈를 확인할 수 있다. testX, testY는 검증용 데이터셋 이다. "
      ],
      "metadata": {
        "id": "z3s-NzBAI3PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
        "# 입력 데이터인 trainX 사이즈를 확인하기 \n",
        "print(trainX.shape)\n",
        "# 실제 입력데이터 60000개 중 첫번째것의 실제 이미지 데이터를 확인하기 \n",
        "print(trainX[0])\n",
        "# 실제 출력데이터 60000개 중 첫번째것을 확인하기 \n",
        "print(trainY[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDQIHQcHJHCg",
        "outputId": "dddcd546-0060-46fd-e090-38c361855d1f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "[[[ 59  62  63]\n",
            "  [ 43  46  45]\n",
            "  [ 50  48  43]\n",
            "  ...\n",
            "  [158 132 108]\n",
            "  [152 125 102]\n",
            "  [148 124 103]]\n",
            "\n",
            " [[ 16  20  20]\n",
            "  [  0   0   0]\n",
            "  [ 18   8   0]\n",
            "  ...\n",
            "  [123  88  55]\n",
            "  [119  83  50]\n",
            "  [122  87  57]]\n",
            "\n",
            " [[ 25  24  21]\n",
            "  [ 16   7   0]\n",
            "  [ 49  27   8]\n",
            "  ...\n",
            "  [118  84  50]\n",
            "  [120  84  50]\n",
            "  [109  73  42]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[208 170  96]\n",
            "  [201 153  34]\n",
            "  [198 161  26]\n",
            "  ...\n",
            "  [160 133  70]\n",
            "  [ 56  31   7]\n",
            "  [ 53  34  20]]\n",
            "\n",
            " [[180 139  96]\n",
            "  [173 123  42]\n",
            "  [186 144  30]\n",
            "  ...\n",
            "  [184 148  94]\n",
            "  [ 97  62  34]\n",
            "  [ 83  53  34]]\n",
            "\n",
            " [[177 144 116]\n",
            "  [168 129  94]\n",
            "  [179 142  87]\n",
            "  ...\n",
            "  [216 184 140]\n",
            "  [151 118  84]\n",
            "  [123  92  72]]]\n",
            "[6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**입력 이미지 데이터 노말라이징** <br>\n",
        "입력 이미지 데이터는 정수의 배열로 데이터가 구성되어 있다. 이 데이터는 0 ~ 255까지의 숫자이다. 이 숫자를 0 ~ 1사이의 값으로 변경하는 것이 텐서플로에서 처리하기 쉽다.노말라이징은 입력 이미지 데이터인 trainX, testX가 대상이다. "
      ],
      "metadata": {
        "id": "H9Xa_jm4Kc6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = trainX.astype(\"float\")/255\n",
        "testX = testX.astype(\"float\")/255\n",
        "# trainX[0]의 정수 데이터들이 노말라이징 된 것을 확인한다.\n",
        "print(trainX[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu8CEj2fKx_0",
        "outputId": "7ce052f2-fff0-442e-8153-50700adff011"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.23137255 0.24313725 0.24705882]\n",
            "  [0.16862745 0.18039216 0.17647059]\n",
            "  [0.19607843 0.18823529 0.16862745]\n",
            "  ...\n",
            "  [0.61960784 0.51764706 0.42352941]\n",
            "  [0.59607843 0.49019608 0.4       ]\n",
            "  [0.58039216 0.48627451 0.40392157]]\n",
            "\n",
            " [[0.0627451  0.07843137 0.07843137]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.07058824 0.03137255 0.        ]\n",
            "  ...\n",
            "  [0.48235294 0.34509804 0.21568627]\n",
            "  [0.46666667 0.3254902  0.19607843]\n",
            "  [0.47843137 0.34117647 0.22352941]]\n",
            "\n",
            " [[0.09803922 0.09411765 0.08235294]\n",
            "  [0.0627451  0.02745098 0.        ]\n",
            "  [0.19215686 0.10588235 0.03137255]\n",
            "  ...\n",
            "  [0.4627451  0.32941176 0.19607843]\n",
            "  [0.47058824 0.32941176 0.19607843]\n",
            "  [0.42745098 0.28627451 0.16470588]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.81568627 0.66666667 0.37647059]\n",
            "  [0.78823529 0.6        0.13333333]\n",
            "  [0.77647059 0.63137255 0.10196078]\n",
            "  ...\n",
            "  [0.62745098 0.52156863 0.2745098 ]\n",
            "  [0.21960784 0.12156863 0.02745098]\n",
            "  [0.20784314 0.13333333 0.07843137]]\n",
            "\n",
            " [[0.70588235 0.54509804 0.37647059]\n",
            "  [0.67843137 0.48235294 0.16470588]\n",
            "  [0.72941176 0.56470588 0.11764706]\n",
            "  ...\n",
            "  [0.72156863 0.58039216 0.36862745]\n",
            "  [0.38039216 0.24313725 0.13333333]\n",
            "  [0.3254902  0.20784314 0.13333333]]\n",
            "\n",
            " [[0.69411765 0.56470588 0.45490196]\n",
            "  [0.65882353 0.50588235 0.36862745]\n",
            "  [0.70196078 0.55686275 0.34117647]\n",
            "  ...\n",
            "  [0.84705882 0.72156863 0.54901961]\n",
            "  [0.59215686 0.4627451  0.32941176]\n",
            "  [0.48235294 0.36078431 0.28235294]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**출력 데이터셋 라벨 바이나리징** <br>\n",
        "CIFAR10 출력 데이터셋 즉 라벨값은 0 ~ 9사이의 정수이다. 이 정수를 바이너리 벡터화 하는 것이 라벨바이나리징인데 이것을 실행한다. <br>\n",
        "2 -> [0 0 1 0 0 0 0 0 0 0 0]"
      ],
      "metadata": {
        "id": "V9CSx4enMIDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainY[0])\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.fit_transform(testY)\n",
        "print(trainY[0]) # 라벨바이나리징 전후를 비교하기 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU4c7ajfM0cB",
        "outputId": "3c81a662-9b09-4cb0-a578-5c4898c56f8f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6]\n",
            "[0 0 0 0 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**라벨 데이터의 숫자 맵핑** <br>\n",
        "CIFAR10 10개의 데이터의 이름을 숫자와 맵핑한다. 여기서는 참고로만 사용한다. 실제 코드에는 사용하지 않는다.   "
      ],
      "metadata": {
        "id": "SyWWWq5ELu6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "\t\"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "metadata": {
        "id": "lnKaSBIzM7f_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN 모델을 구성하기전 준비** <br>\n",
        "CNN 모델을 구성하기 위해서 사전 준비를 한다. 먼저 경사하강법을 실행하는 옵티마이저는 SGD로 정한다. 러닝레이트는 0,01로 한다.입력 이미지는 32x32x3 이다. "
      ],
      "metadata": {
        "id": "4fUvivY3QNvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = SGD(lr=0.01)\n",
        "\n",
        "height = 32\n",
        "width = 32\n",
        "depth =3\n",
        "model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "\tinputShape = (depth, height, width)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG88qGSJQNeX",
        "outputId": "7e36f6a3-febf-4f0d-863b-d4291f8a05bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 구성 <br>\n",
        "1개의 컨볼루션 레이어, 1개의 댄스레이어(기존 신경망 레이어)로 구성된 CNN 모델을 만든다. 컨볼루션 레이어의 액티베이션 함수는 relu, 댄스레이어의 액티베이션 함수는 softmax를 사용한다. "
      ],
      "metadata": {
        "id": "c_h9BTp3Qx4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "metadata": {
        "id": "hdmDcAzmQ0C5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델의 구성** <br>\n",
        "옵티마이저, 손실함수, 메트릭을 정해주고 CNN 신경망을 구성한다. "
      ],
      "metadata": {
        "id": "aCFqaxxLROI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"] )\n"
      ],
      "metadata": {
        "id": "SfDkuqTKRdMW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델 트레이닝** <br>\n",
        "이제 CNN이 구성되었고, trainX, trainY 데이터셋을 이용해서 트레이닝 데이터를 진행한다. testX testY로 검증을 한다. 총 epochs는 40이다. "
      ],
      "metadata": {
        "id": "L_8f9BbyRgAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=32, epochs =40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urblFud4Ru0f",
        "outputId": "f6cab7c8-0e4c-419a-d292-eb151b860f49"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.8082 - accuracy: 0.3645 - val_loss: 1.6400 - val_accuracy: 0.4285\n",
            "Epoch 2/40\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 1.5555 - accuracy: 0.4613 - val_loss: 1.4934 - val_accuracy: 0.4769\n",
            "Epoch 3/40\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.3933 - accuracy: 0.5142 - val_loss: 1.4272 - val_accuracy: 0.4922\n",
            "Epoch 4/40\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3078 - accuracy: 0.5444 - val_loss: 1.3102 - val_accuracy: 0.5351\n",
            "Epoch 5/40\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.2602 - accuracy: 0.5606 - val_loss: 1.2988 - val_accuracy: 0.5416\n",
            "Epoch 6/40\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 1.2215 - accuracy: 0.5744 - val_loss: 1.2854 - val_accuracy: 0.5420\n",
            "Epoch 7/40\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 1.1896 - accuracy: 0.5871 - val_loss: 1.3897 - val_accuracy: 0.5192\n",
            "Epoch 8/40\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.1618 - accuracy: 0.5954 - val_loss: 1.2718 - val_accuracy: 0.5485\n",
            "Epoch 9/40\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 1.1373 - accuracy: 0.6035 - val_loss: 1.3980 - val_accuracy: 0.5160\n",
            "Epoch 10/40\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.1114 - accuracy: 0.6132 - val_loss: 1.2239 - val_accuracy: 0.5707\n",
            "Epoch 11/40\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.0906 - accuracy: 0.6222 - val_loss: 1.2686 - val_accuracy: 0.5526\n",
            "Epoch 12/40\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0702 - accuracy: 0.6291 - val_loss: 1.3148 - val_accuracy: 0.5438\n",
            "Epoch 13/40\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 1.0477 - accuracy: 0.6369 - val_loss: 1.2484 - val_accuracy: 0.5628\n",
            "Epoch 14/40\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 1.0301 - accuracy: 0.6426 - val_loss: 1.2937 - val_accuracy: 0.5453\n",
            "Epoch 15/40\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 1.0089 - accuracy: 0.6495 - val_loss: 1.2358 - val_accuracy: 0.5744\n",
            "Epoch 16/40\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.9936 - accuracy: 0.6548 - val_loss: 1.1976 - val_accuracy: 0.5818\n",
            "Epoch 17/40\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.9748 - accuracy: 0.6655 - val_loss: 1.2371 - val_accuracy: 0.5699\n",
            "Epoch 18/40\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.9587 - accuracy: 0.6694 - val_loss: 1.1986 - val_accuracy: 0.5874\n",
            "Epoch 19/40\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.9408 - accuracy: 0.6744 - val_loss: 1.2436 - val_accuracy: 0.5709\n",
            "Epoch 20/40\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.9250 - accuracy: 0.6823 - val_loss: 1.1849 - val_accuracy: 0.5894\n",
            "Epoch 21/40\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.9080 - accuracy: 0.6867 - val_loss: 1.2068 - val_accuracy: 0.5850\n",
            "Epoch 22/40\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.8903 - accuracy: 0.6932 - val_loss: 1.2364 - val_accuracy: 0.5758\n",
            "Epoch 23/40\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.8745 - accuracy: 0.6978 - val_loss: 1.2488 - val_accuracy: 0.5731\n",
            "Epoch 24/40\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.8567 - accuracy: 0.7061 - val_loss: 1.2297 - val_accuracy: 0.5799\n",
            "Epoch 25/40\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.8410 - accuracy: 0.7110 - val_loss: 1.2157 - val_accuracy: 0.5830\n",
            "Epoch 26/40\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.8247 - accuracy: 0.7172 - val_loss: 1.1820 - val_accuracy: 0.6009\n",
            "Epoch 27/40\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.8114 - accuracy: 0.7208 - val_loss: 1.2136 - val_accuracy: 0.5883\n",
            "Epoch 28/40\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7978 - accuracy: 0.7251 - val_loss: 1.2423 - val_accuracy: 0.5874\n",
            "Epoch 29/40\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.7832 - accuracy: 0.7314 - val_loss: 1.2073 - val_accuracy: 0.5946\n",
            "Epoch 30/40\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.7704 - accuracy: 0.7354 - val_loss: 1.2228 - val_accuracy: 0.5894\n",
            "Epoch 31/40\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.7545 - accuracy: 0.7405 - val_loss: 1.3308 - val_accuracy: 0.5619\n",
            "Epoch 32/40\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7432 - accuracy: 0.7449 - val_loss: 1.1935 - val_accuracy: 0.6019\n",
            "Epoch 33/40\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7303 - accuracy: 0.7507 - val_loss: 1.2532 - val_accuracy: 0.5856\n",
            "Epoch 34/40\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7194 - accuracy: 0.7534 - val_loss: 1.2268 - val_accuracy: 0.5953\n",
            "Epoch 35/40\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.7065 - accuracy: 0.7602 - val_loss: 1.2370 - val_accuracy: 0.5917\n",
            "Epoch 36/40\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6959 - accuracy: 0.7636 - val_loss: 1.2577 - val_accuracy: 0.5898\n",
            "Epoch 37/40\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6835 - accuracy: 0.7665 - val_loss: 1.2395 - val_accuracy: 0.5898\n",
            "Epoch 38/40\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6742 - accuracy: 0.7703 - val_loss: 1.2041 - val_accuracy: 0.6071\n",
            "Epoch 39/40\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6628 - accuracy: 0.7736 - val_loss: 1.2687 - val_accuracy: 0.5911\n",
            "Epoch 40/40\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6514 - accuracy: 0.7779 - val_loss: 1.2353 - val_accuracy: 0.6065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**트레이닝 결과 확인하기** <br> \n",
        "트레이닝 한 결과를 확인한다. 실제로 CIFAR10 데이터셋은 CNN을 사용해도 예측률이 60$정도로 그리 좋지는 않다. 이것은 데이터셋의 해상도가 너무 낮고 데이터숫자가 많지 않아서 발생하는 현상이다. "
      ],
      "metadata": {
        "id": "MlvRVMfxSAyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=labelNames))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va560YiUTcbB",
        "outputId": "f9922e19-aa36-40f1-b4a1-a5184802b260"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.55      0.77      0.64      1000\n",
            "  automobile       0.73      0.72      0.72      1000\n",
            "        bird       0.55      0.35      0.43      1000\n",
            "         cat       0.44      0.45      0.45      1000\n",
            "        deer       0.57      0.51      0.54      1000\n",
            "         dog       0.53      0.44      0.48      1000\n",
            "        frog       0.71      0.71      0.71      1000\n",
            "       horse       0.58      0.75      0.66      1000\n",
            "        ship       0.75      0.65      0.70      1000\n",
            "       truck       0.66      0.70      0.68      1000\n",
            "\n",
            "    accuracy                           0.61     10000\n",
            "   macro avg       0.61      0.61      0.60     10000\n",
            "weighted avg       0.61      0.61      0.60     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN 추론파일 저장하기** <br>\n",
        "트레이닝된 추론파일을 다음에 사용하기 위해서 디스크에 저장한다. "
      ],
      "metadata": {
        "id": "yHeYut30UAGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cifar10_cnn.h5')"
      ],
      "metadata": {
        "id": "y8XzrKLmUAvC"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}