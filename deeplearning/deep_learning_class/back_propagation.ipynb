{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "back-propagation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1wwtlSjhmSy"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "    def __init__(self, w, b):\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "\n",
        "    def feedForword(self, input):\n",
        "\n",
        "        # output y = f(\\sigma)\n",
        "        # \\sigma = w * input x + b\n",
        "        # for multiple inputs,\n",
        "        # \\sigma = w0 * input x0 + w1 * input x1 + ... + b\n",
        "\n",
        "        sigma = self.w * input + self.b\n",
        "        output = self.getActivation(sigma)\n",
        "\n",
        "        self.input = input\n",
        "        self.output = output\n",
        "\n",
        "        return output\n",
        "\n",
        "    def getActivation(self, x):\n",
        "        # for linear or identity activation function\n",
        "        return x\n",
        "\n",
        "        # for ReLU activation function\n",
        "        # return max([0.0, x])\n",
        "\n",
        "    def getActGrad(self, x):\n",
        "        # for linear or identity activation function\n",
        "        return 1.0\n",
        "\n",
        "        # for ReLU\n",
        "        # if x > 0.0: return x\n",
        "        # else: return 0.0\n",
        "\n",
        "    def propBackword(self, target):\n",
        "\n",
        "        # alpha\n",
        "        a = 0.1\n",
        "\n",
        "        self.w = self.w - a*(self.output - target)*self.getActGrad(self.output)*self.input\n",
        "        self.b = self.b - a*(self.output - target)*self.getActGrad(self.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단일노드 퍼셉트론 백프로퍼게이션 클래스 "
      ],
      "metadata": {
        "id": "GWkZDOl9hy3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = Neuron(2.0, 1.0)"
      ],
      "metadata": {
        "id": "vLg_MApMh7Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "백프로퍼게이션 객체 생성. 계수 W 2.0 바이어스 b 1.0"
      ],
      "metadata": {
        "id": "qrX5JXKXh_jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for unused in range(1, 100):\n",
        "    print('Input 1.0 -> Output {}'.format(neuron.feedForword(1.0)))\n",
        "    neuron.propBackword(4.0)"
      ],
      "metadata": {
        "id": "K5mowuDuiHuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "백프로퍼게이션 진행 "
      ],
      "metadata": {
        "id": "81atyjhriUgz"
      }
    }
  ]
}