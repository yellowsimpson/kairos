{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_XOR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X5bqNLhYkUeo"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "numpy 임포트 "
      ],
      "metadata": {
        "id": "ElfZHBpGku-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, layers, alpha=0.1):\n",
        "        self.W = [] \n",
        "        self.layers = layers  # list [ 2, 2, 2, 1]\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # 계수 생성 loop\n",
        "        for i in np.arange(0, len(layers) - 2):\n",
        "            # len(layer) -2 -> out -마지막 hidden layer 제외\n",
        "            w = np.random.randn(layers[i]+1 ,layers[i+1]+1)\n",
        "            self.W.append(w/np.sqrt(layers[i]))\n",
        "        # 마지막 hidden - out 사이의 계수 \n",
        "        w = np.random.randn(layers[-2]+1, layers[-1])\n",
        "        self.W.append(w/np.sqrt(layers[-2]))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1.0 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_deriv(self, x):\n",
        "        return x * (1 - x)\n",
        "    # X = np.array([[ 0,0], [ 0,1], [1,0], [0,0]])\n",
        "    # y = np.array([[0], [1], [1], [0]])\n",
        "    def fit(self, X, y, epochs=1000):\n",
        "        # 아래 코드는 4x2 행렬에 바이어스를 넣어서 4x3 행렬만들기\n",
        "        X = np.c_[X, np.ones((X.shape[0]))] # X.shape[0] = 4\n",
        "        #print(X)\n",
        "        for epoch in np.arange(0, epochs):\n",
        "            for (x, target) in zip(X, y): \n",
        "                # x = [0 0 1] target = [0] \n",
        "                #print(x, target)\n",
        "                self.fit_partial(x, target)\n",
        "\n",
        "    def fit_partial(self, x, y):\n",
        "        # x = [ 0 0 1] y = [0]\n",
        "        A = [np.atleast_2d(x)]\n",
        "        # feed \n",
        "        for layers in np.arange(0, len(self.W)):\n",
        "            net = A[layers].dot(self.W[layers])\n",
        "            out = self.sigmoid(net)\n",
        "            A.append(out)\n",
        "        # A= [array([[0., 0., 1.]]), array([[0.54067744, 0.51712677, 0.26921834]]), array([[0.50808391, 0.57745501, 0.56186676]]), array([[0.4979378]])]\n",
        "        error = A[-1] - y \n",
        "        D = [error * self.sigmoid_deriv(A[-1])]\n",
        "        for layers in np.arange(len(A) -2, 0, -1):\n",
        "            delta = D[-1].dot(self.W[layers].T)\n",
        "            delta = delta*self.sigmoid_deriv(A[layers])\n",
        "            D.append(delta)\n",
        "        #print(D)\n",
        "        D = D[::-1]\n",
        "        for layer in np.arange(0, len(self.W)):\n",
        "            self.W[layer] += -self.alpha * A[layer].T.dot(D[layer])\n",
        "\n",
        "    def predict(self, X):  # X = [0 1]\n",
        "        p = np.atleast_2d(X)\n",
        "        p = np.c_[p, np.ones((p.shape[0]))]\n",
        "        for layer in np.arange(0, len(self.W)):\n",
        "            p = self.sigmoid(np.dot(p, self.W[layer]))\n",
        "        return p"
      ],
      "metadata": {
        "id": "yBSseZxYkxxz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다층 퍼셉트론 클래스 "
      ],
      "metadata": {
        "id": "FCEREn_1k5ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn = NeuralNetwork([2, 2, 1], 0.5)"
      ],
      "metadata": {
        "id": "1aLUUj05k83o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다층 퍼셉트론 클래스 객체 생성, 1 hidden layer, learning rate 0.5"
      ],
      "metadata": {
        "id": "k1cJfQjAlBYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[ 0,0], [ 0,1], [1,0], [1,1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "nn.fit(X, y, 1000)"
      ],
      "metadata": {
        "id": "M8cTBvxWlR24"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XOR 입력 데이터 정의, 출력값 정의, 트레이닝(back-propagation)"
      ],
      "metadata": {
        "id": "GDwXPRyKlVCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for (x, target) in zip(X, y):\n",
        "    pred = nn.predict(x)[0][0]\n",
        "    step = 1 if pred > 0.5 else 0\n",
        "    print(target[0], pred, step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1RpHkpblbBB",
        "outputId": "5289f4ab-03a2-42d4-842d-381ae5fda66e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.0925828182821094 0\n",
            "1 0.8934111980967061 1\n",
            "1 0.9089412809262902 1\n",
            "0 0.07623169645589378 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "feed-forward 예측 "
      ],
      "metadata": {
        "id": "BoFZxCF2le1Z"
      }
    }
  ]
}